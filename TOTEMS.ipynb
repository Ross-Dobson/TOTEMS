{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "argv": [
        "/opt/anaconda3/envs/TOTEMS/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "env": null,
      "interrupt_mode": "signal",
      "language": "python",
      "metadata": null,
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "name": "TOTEMS.ipynb",
    "colab": {
      "name": "TOTEMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mSIw06YxR1-2"
      },
      "source": [
        "# TOTEMS - Tidal Orbital decay Timing Extrapolation & Modelling Software"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "q2zAv4MrR1-4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Import curve fitting (Which is what we need for tidal decay)\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "#Import pylightcurve, used for BJD HJD conversions - thanks to Angelos Tsiaras\n",
        "import pylightcurve as plc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wbUOwVtgR1-5"
      },
      "source": [
        "%matplotlib notebook\n",
        "# if this isn't in a separate cell, sometimes doesn't work right\n",
        "# magic commands are weird, to say the least.\n",
        "\n",
        "# TODO - use structured or recorded arrays with boolean masks, rather than repeatedly iterating"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dgJKf-AJR1-5"
      },
      "source": [
        "First function: gets the relevant data for the exoplanet from the [http://var2.astro.cz/ETD/](Exoplanet Transit\n",
        "Database). Use this if you don't\n",
        "have any archive data of your own to use, though really any data from a recent paper will probably be better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV8gRBY_SJ65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "cf8da965-a1d9-4630-cd54-f06fc484ae3b"
      },
      "source": [
        "def get_etd_data(right_ascension, declination, url):\n",
        "    \"\"\"Imports the data from ETD. Uses RA & Dec to convert HJD_UTC to BJD_TDB.\n",
        "    \n",
        "    Args:\n",
        "        right_ascension: the right ascension in hh mm ss.ss\n",
        "        declination: the declination in dd mm ss.ss\n",
        "        url: the URL of the ETD .csv datafile\n",
        "\n",
        "    Returns:\n",
        "        data: a Pandas DataFrame with no, bjd, mid_err, epoch, dq. These are the\n",
        "          number (on ETD's list), the mid-time in BJD_TDB, the uncertainty of\n",
        "          the mid-time, the epoch number based on the t_0 and period on ETD, and\n",
        "          the ETD Data Quality factor, where 1 is best and 5 is worst.\n",
        "        p_0: the period at epoch=0\n",
        "        t_0: the mid-time at epoch=0\n",
        "    \"\"\"\n",
        "\n",
        "    ### P_0 AND t_0 ###\n",
        "\n",
        "    # Load in the row, split in two via delimeter choice.\n",
        "    p_str, t_str = np.loadtxt(url, dtype=str, encoding='unicode_escape', delimiter=', ', skiprows=2, max_rows=1)\n",
        "    \n",
        "    # Now get just the number, lose everything else.\n",
        "    for possibility in p_str.split():\n",
        "        try:\n",
        "            str(float(possibility))\n",
        "            p_0 = possibility\n",
        "        except ValueError:\n",
        "            pass # if its not the number, move on\n",
        "    for possibility in t_str.split():\n",
        "        try:\n",
        "            str(float(possibility))\n",
        "            t_0 = possibility\n",
        "        except ValueError:\n",
        "            pass # if its not the number, move on\n",
        "\n",
        "    ### TRANSIT DATA ###\n",
        "\n",
        "    # Columns that we want\n",
        "    csv_headers = ['#', 'HJDmid', 'HJDmid Error', 'Epoch', 'DQ']\n",
        "\n",
        "    # What we want to name the columns.\n",
        "    cols = ['tmid', 'err', 'epoch', 'DQ']\n",
        "\n",
        "    # Now to import the actual transit data.\n",
        "    data = pd.read_csv(url, delimiter=';', header=0, index_col=0,\n",
        "                       usecols=csv_headers, skiprows=4)\n",
        "    \n",
        "    # Set the columns to the names we want\n",
        "    data.index.rename('no', inplace=True)  # row header\n",
        "    data.columns = cols  #columns\n",
        "\n",
        "    # Convert from the truncated HJD to the full HJD\n",
        "    data['tmid'] = data['tmid'].apply(lambda x: x + 2400000)\n",
        "\n",
        "    # Assuming (fairly certain) ETD uses HJD_UTC, let's convert to BJD_TDB.\n",
        "    # Of course, it might be worth checking that each individual data point\n",
        "    # is actually in HJD, rather than e.g. BJD already, as ETD doesn't check it.\n",
        "    ra_dec_string = right_ascension+\" \"+declination\n",
        "    ra, dec = plc.ra_dec_string_to_deg(ra_dec_string)\n",
        "\n",
        "    # Convert to BJD_TDB. N.B. we assume uncertainty remains the same.\n",
        "    bjd = np.array([])\n",
        "    for (col, value) in data['tmid'].iteritems():\n",
        "        bjd = np.append(bjd, plc.hjd_utc_to_bjd_tdb(ra, dec, value))\n",
        "    \n",
        "    data['tmid'] = bjd\n",
        "    \n",
        "    return data, p_0, t_0\n",
        "\n",
        "mydf, p_0, t_0 = get_etd_data('06 30 32.79', '+29 40 20.26', 'http://var2.astro.cz/ETD/ascii-etd.php?id=246&STARNAME=WASP-12&PLANET=b&PER=1.0914222&EPOCH=2454508.97605')\n",
        "\n",
        "mydf"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/optimize/minpack.py:808: OptimizeWarning: Covariance of the parameters could not be estimated\n",
            "  category=OptimizeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tmid</th>\n",
              "      <th>err</th>\n",
              "      <th>epoch</th>\n",
              "      <th>DQ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>2.459148e+06</td>\n",
              "      <td>0.00073</td>\n",
              "      <td>4250</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>2.459089e+06</td>\n",
              "      <td>0.00136</td>\n",
              "      <td>4196</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>2.458930e+06</td>\n",
              "      <td>0.00052</td>\n",
              "      <td>4051</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>2.458906e+06</td>\n",
              "      <td>0.00060</td>\n",
              "      <td>4029</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>2.458895e+06</td>\n",
              "      <td>0.00263</td>\n",
              "      <td>4019</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.454841e+06</td>\n",
              "      <td>0.00047</td>\n",
              "      <td>304</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.454837e+06</td>\n",
              "      <td>0.00130</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.454837e+06</td>\n",
              "      <td>0.00156</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.454836e+06</td>\n",
              "      <td>0.00060</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.454509e+06</td>\n",
              "      <td>0.00020</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             tmid      err  epoch  DQ\n",
              "no                                   \n",
              "262  2.459148e+06  0.00073   4250   3\n",
              "261  2.459089e+06  0.00136   4196   2\n",
              "260  2.458930e+06  0.00052   4051   1\n",
              "259  2.458906e+06  0.00060   4029   2\n",
              "258  2.458895e+06  0.00263   4019   3\n",
              "..            ...      ...    ...  ..\n",
              "5    2.454841e+06  0.00047    304   1\n",
              "4    2.454837e+06  0.00130    301   4\n",
              "3    2.454837e+06  0.00156    301   3\n",
              "2    2.454836e+06  0.00060    300   2\n",
              "1    2.454509e+06  0.00020      0   1\n",
              "\n",
              "[262 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LIYzLQEiR1-6"
      },
      "source": [
        "def filter_etd_data(no, bjd, mid_err, epoch, dq, filter_dq):\n",
        "    \"\"\"Filters ETD data. Checks uncertainty exists. Returns only datapoints with DQ equal or better than specified\n",
        "    value. N.B. DQ 1 is best, 5 is worst.\n",
        "    Inputs:\n",
        "    - no\n",
        "    - bjd\n",
        "    - mid_err\n",
        "    - epoch\n",
        "    - dq\n",
        "    - filter_dq\n",
        "    Outputs:\n",
        "    - filteredData, the filtered data array (of arrays). Contains three arrays: BJD mid-time, uncertainty, and epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Let's filter for \"good\" data. I don't trust data without a tmid uncertainty, so check it exists/isn't 0\n",
        "    good_data=[ [],[],[],[],[] ]\n",
        "    for i,err in enumerate(mid_err):\n",
        "        if err < 0:\n",
        "            good_data[0].append(no[i])\n",
        "            good_data[1].append(bjd[i])\n",
        "            good_data[2].append(mid_err[i])\n",
        "            good_data[3].append(epoch[i])\n",
        "            good_data[4].append(dq[i])\n",
        "\n",
        "    # the plan: one array, contains three arrays - these three arrays are for mid, mid_err, epoch\n",
        "    # we don't bother preserving no., it was just imported to be used basically as a debugging tool\n",
        "    # and dq is pointless once we've filtered. This also makes the addition of non-ETD data far easier\n",
        "    filtered_data = [[],[],[]]\n",
        "\n",
        "    for i,good_dq in enumerate(good_data[4]): # for each entry in the data\n",
        "        if good_dq <= filter_dq: # check the DQ vs the specified DQ argument. If better...\n",
        "\n",
        "            # ...then add the data to each of the three arrays in filteredData that we care about\n",
        "            filtered_data[0].append(good_data[1][i])\n",
        "            filtered_data[1].append(good_data[2][i])\n",
        "            filtered_data[2].append(good_data[3][i])\n",
        "\n",
        "    return filtered_data # return the data array containing only the transits that's been filtered by DQ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3L6BNtPxR1-6"
      },
      "source": [
        "## Statistics functions\n",
        "\n",
        "These functions are for the $\\chi^2$ comparison. I sincerely doubt that I haven't accidentally reinvented the wheel - functions for this probably already exist. However, it's so simple, I've not exactly wasted hours on these.\n",
        "\n",
        "Equations are from \"Measurements and Their Uncertainties: A Practical Guide to Modern Error Analysis: Hughes and\n",
        "Hase 2010\".\n",
        "\n",
        "$$ \\chi^2 = \\sum_i{\\frac{y_i-y(x_i)}{\\alpha_i^2}}$$\n",
        "\n",
        "$\\nu$ is the degrees of freedom: the number of datapoints minus the number of fitted parameters. We divide $\\chi^2$ by\n",
        " $\\nu$ to obtain the reduced chi-squared, as follows:\n",
        "\n",
        "$$ \\chi^2_\\text{reduced} = \\frac{\\chi^2}{\\nu} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iRSRG4WAR1-6"
      },
      "source": [
        "def chi_squared(y_i,yx,alpha):\n",
        "    \"\"\"Calculates the unreduced chi squared.\n",
        "    Inputs:\n",
        "    - y_i, the array of observed y value (the y_i in the formula)\n",
        "    - yx, the array of y values of the fitted line (the y(x) in the formula )\n",
        "    - alpha, array of error in y, in the same units as y\n",
        "    Outputs:\n",
        "    - chi2, the unreduced chi squared value\n",
        "    \"\"\"\n",
        "\n",
        "    chi2=0\n",
        "    for i,y in enumerate(y_i):\n",
        "        chi2 += ((y-yx[i])**2) / (alpha[i]**2)\n",
        "    return chi2\n",
        "\n",
        "def reduced_chi_squared(y,yx,alpha,m):\n",
        "    \"\"\"Calculates the reduced chi squared from the raw data: just chisq divided by degrees of freedom\n",
        "    Degree of freedom is just number of observations n - number of fitted parameters m\n",
        "    where n is just the number of y (or y(x) or x) values\n",
        "    Inputs:\n",
        "    - y, array of actual observed y value (the y_i in the formula)\n",
        "    - yx, array of y value of the fitted line (the y(x) in the formula )\n",
        "    - alpha, array of error in y, in the same units as y\n",
        "    - m, the number of fitted parameters.\n",
        "    Outputs:\n",
        "    - chi2, the unreduced chi squared value\n",
        "    \"\"\"\n",
        "    n = len(y) # number of observations/datapoints\n",
        "    dof = n-m # degree of freedom, m is fitted params\n",
        "    chi2 = chi_squared(y,yx,alpha) # get the unreduced chi squared\n",
        "    reduced_chi2 = chi2/dof # reduce it\n",
        "    return reduced_chi2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-6e7j33BR1-6"
      },
      "source": [
        "# TODO stop using globals. Consider OO principles, or structured/recorded arrays.\n",
        "# TODO error handling and exceptions need to be added, because this too is currently a mess.\n",
        "\n",
        "def  add_own_data(filename):\n",
        "    \"\"\"Function to add archive data and your own data. Put it into three columns: tmid, error, and type of JD (Either\n",
        "     \"HJD\" or \"BJD\", assuming HJD_UTC or BJD_TDB. Will be asked for the P_0: supply your own or use ETDs. For t_0,\n",
        "     assumes earliest tmid given. NOTE: if ETD data has been used, it will force the ETD values.\n",
        "    Inputs:\n",
        "    - filename, the name/path of your data table (just use a csv)\n",
        "    Outputs:\n",
        "    - bjd, array of BJD_TDB mid-transit-times\n",
        "    - mid_err, the uncertainty of those tmids\n",
        "    - epoch, transits since t_0\n",
        "    - t_0, midtime at epoch=0\n",
        "    - p_0, the period at epoch=0\n",
        "    \"\"\"\n",
        "    # TODO don't do this\n",
        "    global url\n",
        "    global ra\n",
        "    global dec\n",
        "\n",
        "    # import all the data\n",
        "    mid,mid_err,jd_type = np.genfromtxt(filename, encoding='unicode_escape', delimiter=',', missing_values='',\n",
        "                                            filling_values=-1, unpack=True)\n",
        "\n",
        "    bjd=[]\n",
        "    # check if we need to convert to BJD\n",
        "    # TODO: error handling needs implementing here\n",
        "    for i,tmid in enumerate(mid):\n",
        "        if jd_type[i] == \"BJD\":\n",
        "            bjd.append(tmid)\n",
        "        elif jd_type[i] == \"HJD\":\n",
        "            bjd.append(plc.hjd_utc_to_bjd_tdb(ra, dec, tmid))\n",
        "        else:\n",
        "            print(\"Something has gone wrong! Your type value needs to be a string of BJD or HJD.\")\n",
        "            # TODO: better way to deal with this, proper exception handling\n",
        "            break\n",
        "\n",
        "    # check if we need to assume a t_0 and p_0, if so, do so\n",
        "    t_0 = 0\n",
        "    p_0 = 0\n",
        "    if not etd_used:\n",
        "        # use the earliest tmid as t_0\n",
        "        t_0 = np.amin(bjd)\n",
        "\n",
        "        # ask for p_0, check it's sensible\n",
        "        p_good = False\n",
        "        while not p_good:\n",
        "            p_0 = input(\"Please input the value of P, in days:\")\n",
        "            if p_0 > 0:\n",
        "                p_good = True\n",
        "                # TODO: a better check than this!\n",
        "    else:\n",
        "        # url should be defined already outside this function, so can just call it because we're bad people that\n",
        "        # aren't obeying proper OO principles\n",
        "        # TODO: obey proper OO principles\n",
        "        p_0, t_0 = p0_t0_from_etd(url)\n",
        "\n",
        "    epoch=[]\n",
        "\n",
        "    # calculate the epoch system - assume closest rounding is correct via np.rint\n",
        "    for i,tmid in enumerate(bjd):\n",
        "        epoch[i] = np.rint((tmid-t_0)/p_0)\n",
        "\n",
        "    #return everything: again, three arrays, two floats\n",
        "    return bjd, mid_err, epoch, p_0, t_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GA4FEg6RR1-6"
      },
      "source": [
        "def sort_etd_own_data(etd_data, own_data):\n",
        "    \"\"\"Sorts the filtered ETD data and user's archive data into the correct order.\n",
        "    Inputs:\n",
        "    -etd_data, an array of ETD data\n",
        "    -own_data, archive data added from literature, may contain user's own datapoint\n",
        "    Outputs:\n",
        "    -sorted_data, the sorted combination of these two datasets\n",
        "    \"\"\"\n",
        "    own_bjd, own_mid_err, own_epoch = own_data\n",
        "    etd_bjd, etd_mid_err, etd_epoch = etd_data\n",
        "    for j in tqdm(range(0, len(own_epoch))):\n",
        "        for i in range(0, len(etd_epoch)):\n",
        "            if (own_epoch[j] >= etd_epoch[i]):\n",
        "                etd_epoch = np.insert(etd_epoch,i,own_epoch[j])\n",
        "                etd_bjd = np.insert(etd_bjd,i,own_bjd[j])\n",
        "                etd_mid_err = np.insert(etd_mid_err,i,own_mid_err[j])\n",
        "                break\n",
        "    # TODO: inefficient, better to add to new array than constantly cycling ETD array?\n",
        "\n",
        "    return [etd_epoch, etd_bjd, etd_mid_err]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeSVYJLTR1-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}